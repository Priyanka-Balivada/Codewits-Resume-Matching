{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrPMChbCmKM_",
        "outputId": "b57bf23e-b62d-4409-c2c7-0a1086293d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Doc2Vec**"
      ],
      "metadata": {
        "id": "8f1hmuiZ0W0i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsS5GDCqqZbT",
        "outputId": "3768b1c6-726f-4fb4-f473-65e3cd1d9e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EipS4hlrH2a",
        "outputId": "27a3caf9-faf5-4264-bf89-74f5faa98476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cwt_zUiqUWQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "842af46e-0ccb-4c64-9f7a-d5d301fb0ee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available job descriptions:\n",
            "1. JD - Security Researcher .pdf\n",
            "2. CWS _ JD _ NodeJS Developer.pdf\n",
            "3. JD - Cloud Security.pdf\n",
            "4. CWS _ JD _ Software Interns.pdf\n",
            "5. JD _ Head of Engineering (Cyber Security SaaS Startup) (1).pdf\n",
            "6. CWS - JD -Interns.pdf\n",
            "Enter the index of the job description you want to compare (1 to 6): 3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   Resume  Similarity Score\n",
              "0         Naukri_MANISHKHULLAR[3y_6m].pdf          0.773564\n",
              "1  Aditya's Resume NEW UPDATED RECENT.pdf          0.460366\n",
              "2                 Resume_Nabaneet (1).pdf          0.449102\n",
              "3                     KALPESH_GHORSE_.pdf          0.403404\n",
              "4                 Nilesh_Pawar_Resume.pdf          0.489674\n",
              "5     Naukri_DikshaDeshbhratar[5y_0m].pdf          0.643385\n",
              "6             Naukri_OmTalathi[5y_0m].pdf          0.464563\n",
              "7                      Bhavik-cv-2024.pdf          0.372014"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef9e6d75-a103-4573-9e55-1433c4bc5b01\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Resume</th>\n",
              "      <th>Similarity Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naukri_MANISHKHULLAR[3y_6m].pdf</td>\n",
              "      <td>0.773564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Aditya's Resume NEW UPDATED RECENT.pdf</td>\n",
              "      <td>0.460366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Resume_Nabaneet (1).pdf</td>\n",
              "      <td>0.449102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KALPESH_GHORSE_.pdf</td>\n",
              "      <td>0.403404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nilesh_Pawar_Resume.pdf</td>\n",
              "      <td>0.489674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Naukri_DikshaDeshbhratar[5y_0m].pdf</td>\n",
              "      <td>0.643385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Naukri_OmTalathi[5y_0m].pdf</td>\n",
              "      <td>0.464563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Bhavik-cv-2024.pdf</td>\n",
              "      <td>0.372014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef9e6d75-a103-4573-9e55-1433c4bc5b01')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef9e6d75-a103-4573-9e55-1433c4bc5b01 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef9e6d75-a103-4573-9e55-1433c4bc5b01');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d8e0c432-203b-4a18-92e6-188d3ecde59f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8e0c432-203b-4a18-92e6-188d3ecde59f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d8e0c432-203b-4a18-92e6-188d3ecde59f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_96a2cb31-6b9c-4581-8000-671c3d71990b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_96a2cb31-6b9c-4581-8000-671c3d71990b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os\n",
        "import nltk\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            text += pdf_reader.pages[page_num].extract_text()\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "def train_doc2vec_model(documents):\n",
        "    model = Doc2Vec(vector_size=20, min_count=2, epochs=50)\n",
        "    model.build_vocab(documents)\n",
        "    model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "    return model\n",
        "\n",
        "def calculate_similarity(model, text1, text2):\n",
        "    vector1 = model.infer_vector(preprocess_text(text1))\n",
        "    vector2 = model.infer_vector(preprocess_text(text2))\n",
        "    return model.dv.cosine_similarities(vector1, [vector2])[0]\n",
        "\n",
        "# Folder paths for resumes and job descriptions\n",
        "resumes_folder = \"resume\"\n",
        "job_descriptions_folder = \"job\"\n",
        "\n",
        "# List all PDF files in the folders\n",
        "resumes_files = [os.path.join(resumes_folder, file) for file in os.listdir(resumes_folder) if file.endswith(\".pdf\")]\n",
        "job_descriptions_files = [os.path.join(job_descriptions_folder, file) for file in os.listdir(job_descriptions_folder) if file.endswith(\".pdf\")]\n",
        "\n",
        "# Load job descriptions from the folder\n",
        "print(\"Available job descriptions:\")\n",
        "for i, job_desc_file in enumerate(job_descriptions_files):\n",
        "    print(f\"{i + 1}. {os.path.basename(job_desc_file)}\")\n",
        "\n",
        "selected_job_index = int(input(\"Enter the index of the job description you want to compare (1 to {}): \".format(len(job_descriptions_files))))\n",
        "selected_job_path = job_descriptions_files[selected_job_index - 1]\n",
        "selected_job_text = extract_text_from_pdf(selected_job_path)\n",
        "\n",
        "# Load all resumes from the folder\n",
        "all_resumes_text = [extract_text_from_pdf(resume_path) for resume_path in resumes_files]\n",
        "\n",
        "# Preprocess the documents and create TaggedDocuments for resumes\n",
        "tagged_resumes = [TaggedDocument(words=preprocess_text(text), tags=[str(i)]) for i, text in enumerate(all_resumes_text)]\n",
        "\n",
        "# Train Doc2Vec model for resumes\n",
        "model_resumes = train_doc2vec_model(tagged_resumes)\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "results_data = {'Resume': [], 'Similarity Score': []}\n",
        "\n",
        "# Compare the selected job description with all resumes\n",
        "for i, resume_text in enumerate(all_resumes_text):\n",
        "    similarity_score = calculate_similarity(model_resumes, resume_text, selected_job_text)\n",
        "    results_data['Resume'].append(os.path.basename(resumes_files[i]))\n",
        "    results_data['Similarity Score'].append(similarity_score)\n",
        "\n",
        "# Create a DataFrame\n",
        "results_df = pd.DataFrame(results_data)\n",
        "results_df\n",
        "# # Plot the results\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.bar(results_df['Resume'], results_df['Similarity Score'], color='blue')\n",
        "# plt.xlabel('Resume')\n",
        "# plt.ylabel('Similarity Score')\n",
        "# plt.title('Similarity Scores between Job Description and Resumes')\n",
        "# plt.xticks(rotation=45, ha='right')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msZKpNpDrJ6O",
        "outputId": "cf7bf0f8-f358-4e7a-f423-457b48e124cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available job descriptions:\n",
            "1. JD - Security Researcher .pdf\n",
            "2. CWS _ JD _ NodeJS Developer.pdf\n",
            "3. JD - Cloud Security.pdf\n",
            "4. CWS _ JD _ Software Interns.pdf\n",
            "5. JD _ Head of Engineering (Cyber Security SaaS Startup) (1).pdf\n",
            "6. CWS - JD -Interns.pdf\n",
            "Enter the index of the job description you want to compare (1 to 6): 3\n",
            "\n",
            "Results Table (sorted by Similarity Score in descending order):\n",
            "                                   Resume  Similarity Score\n",
            "0         Naukri_MANISHKHULLAR[3y_6m].pdf          0.773564\n",
            "5     Naukri_DikshaDeshbhratar[5y_0m].pdf          0.643385\n",
            "4                 Nilesh_Pawar_Resume.pdf          0.489674\n",
            "6             Naukri_OmTalathi[5y_0m].pdf          0.464563\n",
            "1  Aditya's Resume NEW UPDATED RECENT.pdf          0.460366\n",
            "2                 Resume_Nabaneet (1).pdf          0.449102\n",
            "3                     KALPESH_GHORSE_.pdf          0.403404\n",
            "7                      Bhavik-cv-2024.pdf          0.372014\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import nltk\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            text += pdf_reader.pages[page_num].extract_text()\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "def train_doc2vec_model(documents):\n",
        "    model = Doc2Vec(vector_size=20, min_count=2, epochs=50)\n",
        "    model.build_vocab(documents)\n",
        "    model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "    return model\n",
        "\n",
        "def calculate_similarity(model, text1, text2):\n",
        "    vector1 = model.infer_vector(preprocess_text(text1))\n",
        "    vector2 = model.infer_vector(preprocess_text(text2))\n",
        "    return model.dv.cosine_similarities(vector1, [vector2])[0]\n",
        "\n",
        "# Folder paths for resumes and job descriptions\n",
        "resumes_folder = \"resume\"\n",
        "job_descriptions_folder = \"job\"\n",
        "\n",
        "# List all PDF files in the folders\n",
        "resumes_files = [os.path.join(resumes_folder, file) for file in os.listdir(resumes_folder) if file.endswith(\".pdf\")]\n",
        "job_descriptions_files = [os.path.join(job_descriptions_folder, file) for file in os.listdir(job_descriptions_folder) if file.endswith(\".pdf\")]\n",
        "\n",
        "# Load job descriptions from the folder\n",
        "print(\"Available job descriptions:\")\n",
        "for i, job_desc_file in enumerate(job_descriptions_files):\n",
        "    print(f\"{i + 1}. {os.path.basename(job_desc_file)}\")\n",
        "\n",
        "selected_job_index = int(input(\"Enter the index of the job description you want to compare (1 to {}): \".format(len(job_descriptions_files))))\n",
        "selected_job_path = job_descriptions_files[selected_job_index - 1]\n",
        "selected_job_text = extract_text_from_pdf(selected_job_path)\n",
        "\n",
        "# Load all resumes from the folder\n",
        "all_resumes_text = [extract_text_from_pdf(resume_path) for resume_path in resumes_files]\n",
        "\n",
        "# Preprocess the documents and create TaggedDocuments for resumes\n",
        "tagged_resumes = [TaggedDocument(words=preprocess_text(text), tags=[str(i)]) for i, text in enumerate(all_resumes_text)]\n",
        "\n",
        "# Train Doc2Vec model for resumes\n",
        "model_resumes = train_doc2vec_model(tagged_resumes)\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "results_data = {'Resume': [], 'Similarity Score': []}\n",
        "\n",
        "# Compare the selected job description with all resumes\n",
        "for i, resume_text in enumerate(all_resumes_text):\n",
        "    similarity_score = calculate_similarity(model_resumes, resume_text, selected_job_text)\n",
        "    results_data['Resume'].append(os.path.basename(resumes_files[i]))\n",
        "    results_data['Similarity Score'].append(similarity_score)\n",
        "\n",
        "# Create a DataFrame\n",
        "results_df = pd.DataFrame(results_data)\n",
        "\n",
        "# Sort the DataFrame by similarity scores in descending order\n",
        "results_df = results_df.sort_values(by='Similarity Score', ascending=False)\n",
        "\n",
        "# Plot the results using seaborn for a more attractive visualization\n",
        "# plt.figure(figsize=(12, 8))\n",
        "# sns.barplot(x='Resume', y='Similarity Score', data=results_df, palette='viridis')\n",
        "# plt.xlabel('Resume', fontsize=14)\n",
        "# plt.ylabel('Similarity Score', fontsize=14)\n",
        "# plt.title('Similarity Scores between Job Description and Resumes', fontsize=16)\n",
        "# plt.xticks(rotation=45, ha='right')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# Display the results table\n",
        "print(\"\\nResults Table (sorted by Similarity Score in descending order):\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aefzU6KbtvHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2bea24-382a-446e-c3f2-7bf51523237e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install gensim nltk PyPDF2 pandas seaborn matplotlib networkx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMEFq3ayvY7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5beec09-7e1b-45fa-9dba-4e9769775384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available job descriptions:\n",
            "1. JD - Security Researcher .pdf\n",
            "2. CWS _ JD _ NodeJS Developer.pdf\n",
            "3. JD - Cloud Security.pdf\n",
            "4. CWS _ JD _ Software Interns.pdf\n",
            "5. JD _ Head of Engineering (Cyber Security SaaS Startup) (1).pdf\n",
            "6. CWS - JD -Interns.pdf\n",
            "Enter the index of the job description you want to compare (1 to 6): 3\n",
            "\n",
            "Resume with the Highest Similarity Score:\n",
            "Filename: Naukri_MANISHKHULLAR[3y_6m].pdf\n",
            "Similarity Score: 0.773564\n",
            "Extracted Name: ['App Developer', 'App Development', 'Harsh Niwas', 'Git Bash', 'Six Sigma', 'Jest Dec', 'Gast Android', 'System Java', 'Line Follower', 'Of Things']\n",
            "Extracted Email Addresses: []\n",
            "Extracted Contact Numbers: ['9518354126']\n",
            "\n",
            "High-Weighted Keywords:\n",
            "         Keyword  TF-IDF Score\n",
            "358         pune      0.230083\n",
            "13          2019      0.207074\n",
            "150    developer      0.207074\n",
            "47       android      0.161058\n",
            "152  development      0.161058\n",
            "111     complete      0.161058\n",
            "104        cloud      0.138050\n",
            "17          2023      0.138050\n",
            "251         june      0.138050\n",
            "459        using      0.138050\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import nltk\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "import re  # Added import for regular expressions\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            text += pdf_reader.pages[page_num].extract_text()\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "def train_doc2vec_model(documents):\n",
        "    model = Doc2Vec(vector_size=20, min_count=2, epochs=50)\n",
        "    model.build_vocab(documents)\n",
        "    model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "    return model\n",
        "\n",
        "def calculate_similarity(model, text1, text2):\n",
        "    vector1 = model.infer_vector(preprocess_text(text1))\n",
        "    vector2 = model.infer_vector(preprocess_text(text2))\n",
        "    return model.dv.cosine_similarities(vector1, [vector2])[0]\n",
        "\n",
        "# Folder paths for resumes and job descriptions\n",
        "resumes_folder = \"resume\"\n",
        "job_descriptions_folder = \"job\"\n",
        "\n",
        "# List all PDF files in the folders\n",
        "resumes_files = [os.path.join(resumes_folder, file) for file in os.listdir(resumes_folder) if file.endswith(\".pdf\")]\n",
        "job_descriptions_files = [os.path.join(job_descriptions_folder, file) for file in os.listdir(job_descriptions_folder) if file.endswith(\".pdf\")]\n",
        "\n",
        "# Load job descriptions from the folder\n",
        "print(\"Available job descriptions:\")\n",
        "for i, job_desc_file in enumerate(job_descriptions_files):\n",
        "    print(f\"{i + 1}. {os.path.basename(job_desc_file)}\")\n",
        "\n",
        "selected_job_index = int(input(\"Enter the index of the job description you want to compare (1 to {}): \".format(len(job_descriptions_files))))\n",
        "selected_job_path = job_descriptions_files[selected_job_index - 1]\n",
        "selected_job_text = extract_text_from_pdf(selected_job_path)\n",
        "\n",
        "# Load all resumes from the folder\n",
        "all_resumes_text = [extract_text_from_pdf(resume_path) for resume_path in resumes_files]\n",
        "\n",
        "# Preprocess the documents and create TaggedDocuments for resumes\n",
        "tagged_resumes = [TaggedDocument(words=preprocess_text(text), tags=[str(i)]) for i, text in enumerate(all_resumes_text)]\n",
        "\n",
        "# Train Doc2Vec model for resumes\n",
        "model_resumes = train_doc2vec_model(tagged_resumes)\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "results_data = {'Resume': [], 'Similarity Score': []}\n",
        "\n",
        "# Compare the selected job description with all resumes\n",
        "for i, resume_text in enumerate(all_resumes_text):\n",
        "    similarity_score = calculate_similarity(model_resumes, resume_text, selected_job_text)\n",
        "    results_data['Resume'].append(os.path.basename(resumes_files[i]))\n",
        "    results_data['Similarity Score'].append(similarity_score)\n",
        "\n",
        "# Create a DataFrame\n",
        "results_df = pd.DataFrame(results_data)\n",
        "\n",
        "# Find the index of the highest similarity score\n",
        "highest_score_index = results_df['Similarity Score'].idxmax()\n",
        "\n",
        "# Get the filename and full path of the resume with the highest score\n",
        "highest_score_resume = resumes_files[highest_score_index]\n",
        "highest_score_resume_text = all_resumes_text[highest_score_index]\n",
        "\n",
        "# Extract name, email addresses, and contact numbers using regular expressions\n",
        "name_pattern = r'\\b[A-Z][a-z]+ [A-Z][a-z]+\\b'\n",
        "email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "phone_pattern = r'\\b\\d{10}\\b|\\b\\d{3}[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b'\n",
        "\n",
        "names = re.findall(name_pattern, highest_score_resume_text)\n",
        "emails = re.findall(email_pattern, highest_score_resume_text)\n",
        "contacts = re.findall(phone_pattern, highest_score_resume_text)\n",
        "\n",
        "# Combine extracted information into a single string for TF-IDF analysis\n",
        "combined_text = ' '.join([highest_score_resume_text] + names + emails + contacts)\n",
        "\n",
        "# Use TF-IDF to get high-weighted keywords\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform([combined_text])\n",
        "\n",
        "# Get feature names (words) and their corresponding TF-IDF scores\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "tfidf_scores = tfidf_matrix.toarray()[0]\n",
        "\n",
        "# Create a DataFrame to store keywords and their TF-IDF scores\n",
        "keywords_df = pd.DataFrame({'Keyword': feature_names, 'TF-IDF Score': tfidf_scores})\n",
        "\n",
        "# Sort DataFrame by TF-IDF scores in descending order\n",
        "keywords_df = keywords_df.sort_values(by='TF-IDF Score', ascending=False)\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nResume with the Highest Similarity Score:\")\n",
        "print(\"Filename:\", os.path.basename(highest_score_resume))\n",
        "print(\"Similarity Score:\", results_df.loc[highest_score_index, 'Similarity Score'])\n",
        "print(\"Extracted Name:\", names)\n",
        "print(\"Extracted Email Addresses:\", emails)\n",
        "print(\"Extracted Contact Numbers:\", contacts)\n",
        "\n",
        "# Display high-weighted keywords\n",
        "print(\"\\nHigh-Weighted Keywords:\")\n",
        "print(keywords_df.head(10))  # Displaying the top 10 keywords\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FastText**"
      ],
      "metadata": {
        "id": "ywZ6Fp9L0iXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            text += pdf_reader.pages[page_num].extract_text()\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "# Folder paths for resumes and job descriptions\n",
        "resumes_folder = \"resume\"\n",
        "job_descriptions_folder = \"job\"\n",
        "\n",
        "resumes_files = [os.path.join(resumes_folder, file) for file in os.listdir(resumes_folder) if file.endswith(\".pdf\")]\n",
        "job_descriptions_files = [os.path.join(job_descriptions_folder, file) for file in os.listdir(job_descriptions_folder) if file.endswith(\".pdf\")]\n",
        "\n",
        "print(\"Available job descriptions:\")\n",
        "for i, job_desc_file in enumerate(job_descriptions_files):\n",
        "    print(f\"{i + 1}. {os.path.basename(job_desc_file)}\")\n",
        "\n",
        "selected_job_index = int(input(\"Enter the index of the job description you want to compare (1 to {}): \".format(len(job_descriptions_files))))\n",
        "selected_job_path = job_descriptions_files[selected_job_index - 1]\n",
        "selected_job_text = extract_text_from_pdf(selected_job_path)\n",
        "\n",
        "all_resumes_text = [extract_text_from_pdf(resume_path) for resume_path in resumes_files]\n",
        "\n",
        "preprocessed_job_text = preprocess_text(selected_job_text)\n",
        "preprocessed_resumes_text = [preprocess_text(text) for text in all_resumes_text]\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=preprocess_text)\n",
        "\n",
        "vectorizer.fit(all_resumes_text + [selected_job_text])\n",
        "\n",
        "job_tfidf = vectorizer.transform([selected_job_text])\n",
        "resume_tfidf = vectorizer.transform(all_resumes_text)\n",
        "\n",
        "similarity_scores = cosine_similarity(job_tfidf, resume_tfidf)\n",
        "\n",
        "results_data = {'Resume': [], 'Similarity Score': []}\n",
        "\n",
        "for i, resume_file in enumerate(resumes_files):\n",
        "    results_data['Resume'].append(os.path.basename(resume_file))\n",
        "    results_data['Similarity Score'].append(similarity_scores[0][i])\n",
        "\n",
        "results_df = pd.DataFrame(results_data)\n",
        "\n",
        "results_df = results_df.sort_values(by='Similarity Score', ascending=False)\n",
        "\n",
        "# Display the results table\n",
        "print(\"\\nResults Table (sorted by Similarity Score in descending order):\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D5Rnulr0mZS",
        "outputId": "d57be907-d8e7-40fa-828b-1b7d1ad69af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available job descriptions:\n",
            "1. JD - Security Researcher .pdf\n",
            "2. CWS _ JD _ NodeJS Developer.pdf\n",
            "3. JD - Cloud Security.pdf\n",
            "4. CWS _ JD _ Software Interns.pdf\n",
            "5. JD _ Head of Engineering (Cyber Security SaaS Startup) (1).pdf\n",
            "6. CWS - JD -Interns.pdf\n",
            "Enter the index of the job description you want to compare (1 to 6): 3\n",
            "\n",
            "Results Table (sorted by Similarity Score in descending order):\n",
            "                                   Resume  Similarity Score\n",
            "5     Naukri_DikshaDeshbhratar[5y_0m].pdf          0.358460\n",
            "6             Naukri_OmTalathi[5y_0m].pdf          0.330419\n",
            "7                      Bhavik-cv-2024.pdf          0.317824\n",
            "0         Naukri_MANISHKHULLAR[3y_6m].pdf          0.291806\n",
            "4                 Nilesh_Pawar_Resume.pdf          0.281971\n",
            "1  Aditya's Resume NEW UPDATED RECENT.pdf          0.229081\n",
            "3                     KALPESH_GHORSE_.pdf          0.151492\n",
            "2                 Resume_Nabaneet (1).pdf          0.148053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TF-IDF**"
      ],
      "metadata": {
        "id": "VUO8Ey-F02gZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            text += pdf_reader.pages[page_num].extract_text()\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "# Folder paths for resumes and job descriptions\n",
        "resumes_folder = \"resume\"\n",
        "job_descriptions_folder = \"job\"\n",
        "\n",
        "resumes_files = [os.path.join(resumes_folder, file) for file in os.listdir(resumes_folder) if file.endswith(\".pdf\")]\n",
        "job_descriptions_files = [os.path.join(job_descriptions_folder, file) for file in os.listdir(job_descriptions_folder) if file.endswith(\".pdf\")]\n",
        "\n",
        "print(\"Available job descriptions:\")\n",
        "for i, job_desc_file in enumerate(job_descriptions_files):\n",
        "    print(f\"{i + 1}. {os.path.basename(job_desc_file)}\")\n",
        "\n",
        "selected_job_index = int(input(\"Enter the index of the job description you want to compare (1 to {}): \".format(len(job_descriptions_files))))\n",
        "selected_job_path = job_descriptions_files[selected_job_index - 1]\n",
        "selected_job_text = extract_text_from_pdf(selected_job_path)\n",
        "\n",
        "all_resumes_text = [extract_text_from_pdf(resume_path) for resume_path in resumes_files]\n",
        "\n",
        "preprocessed_job_text = preprocess_text(selected_job_text)\n",
        "preprocessed_resumes_text = [preprocess_text(text) for text in all_resumes_text]\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=preprocess_text)\n",
        "\n",
        "vectorizer.fit(all_resumes_text + [selected_job_text])\n",
        "\n",
        "job_tfidf = vectorizer.transform([selected_job_text])\n",
        "resume_tfidf = vectorizer.transform(all_resumes_text)\n",
        "\n",
        "similarity_scores = cosine_similarity(job_tfidf, resume_tfidf)\n",
        "\n",
        "results_data = {'Resume': [], 'Similarity Score': []}\n",
        "\n",
        "for i, resume_file in enumerate(resumes_files):\n",
        "    results_data['Resume'].append(os.path.basename(resume_file))\n",
        "    results_data['Similarity Score'].append(similarity_scores[0][i])\n",
        "\n",
        "results_df = pd.DataFrame(results_data)\n",
        "\n",
        "results_df = results_df.sort_values(by='Similarity Score', ascending=False)\n",
        "\n",
        "# Display the results table\n",
        "print(\"\\nResults Table (sorted by Similarity Score in descending order):\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt_BnVUn1Mgx",
        "outputId": "cbd170d7-52b7-42e0-946a-28e09dc23d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available job descriptions:\n",
            "1. JD - Security Researcher .pdf\n",
            "2. CWS _ JD _ NodeJS Developer.pdf\n",
            "3. JD - Cloud Security.pdf\n",
            "4. CWS _ JD _ Software Interns.pdf\n",
            "5. JD _ Head of Engineering (Cyber Security SaaS Startup) (1).pdf\n",
            "6. CWS - JD -Interns.pdf\n",
            "Enter the index of the job description you want to compare (1 to 6): 3\n",
            "\n",
            "Results Table (sorted by Similarity Score in descending order):\n",
            "                                   Resume  Similarity Score\n",
            "5     Naukri_DikshaDeshbhratar[5y_0m].pdf          0.358460\n",
            "6             Naukri_OmTalathi[5y_0m].pdf          0.330419\n",
            "7                      Bhavik-cv-2024.pdf          0.317824\n",
            "0         Naukri_MANISHKHULLAR[3y_6m].pdf          0.291806\n",
            "4                 Nilesh_Pawar_Resume.pdf          0.281971\n",
            "1  Aditya's Resume NEW UPDATED RECENT.pdf          0.229081\n",
            "3                     KALPESH_GHORSE_.pdf          0.151492\n",
            "2                 Resume_Nabaneet (1).pdf          0.148053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import fitz\n",
        "# PyMuPDF\n",
        "import os\n",
        "import fasttext\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = ''\n",
        "\n",
        "    for page_num in range(doc.page_count):\n",
        "        page = doc[page_num]\n",
        "        text += page.get_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "def clean_and_tokenize(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove newline characters\n",
        "    text = text.replace('\\n', ' ')\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Specify the path to your job description PDF file\n",
        "job_description_pdf_path = 'Software.pdf'\n",
        "\n",
        "# Extract text from job description PDF\n",
        "job_description_text = extract_text_from_pdf(job_description_pdf_path)\n",
        "job_description_text = clean_and_tokenize(job_description_text)\n",
        "\n",
        "# Specify the path to your resume PDF file\n",
        "resume_pdf_path = 'KALPESH_GHORSE_.pdf'\n",
        "\n",
        "# Extract text from resume PDF\n",
        "resume_text = extract_text_from_pdf(resume_pdf_path)\n",
        "resume_text = clean_and_tokenize(resume_text)\n",
        "\n",
        "# Save the plain text files\n",
        "with open('job_description.txt', 'w', encoding='utf-8') as file:\n",
        "    file.write(job_description_text)\n",
        "\n",
        "with open('resume.txt', 'w', encoding='utf-8') as file:\n",
        "    file.write(resume_text)\n",
        "\n",
        "# Train FastText model\n",
        "model = fasttext.train_unsupervised('job_description.txt', model='skipgram')\n",
        "\n",
        "# Get sentence vectors for job description and resume\n",
        "job_description_vector = model.get_sentence_vector(job_description_text)\n",
        "resume_vector = model.get_sentence_vector(resume_text)\n",
        "\n",
        "# Calculate cosine similarity using NumPy\n",
        "similarity = cosine_similarity([job_description_vector], [resume_vector])\n",
        "\n",
        "# Display matching result\n",
        "print(f\"Similarity: {similarity[0][0] * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "DDEECGExCCy0",
        "outputId": "42892722-b3a6-408a-97d3-631f90be3c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'fitz' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-48e47698cca3>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Extract text from job description PDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mjob_description_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_description_pdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mjob_description_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_and_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_description_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-48e47698cca3>\u001b[0m in \u001b[0;36mextract_text_from_pdf\u001b[0;34m(pdf_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fitz' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5deJQ2BpCEib",
        "outputId": "408b0d07-02c9-4218-baea-0a44d61bb156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199775 sha256=b70593020ccd8a59697284e6919169900fd0dfdaa5712efc9e1ffee18b9e42df\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "import re  # Import regular expressions module\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            text += pdf_reader.pages[page_num].extract_text()\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "# Function to extract CGPA from text using regular expressions\n",
        "def extract_cgpa(text):\n",
        "    cgpa_pattern = r'\\b\\d\\.\\d{1,2}\\b'  # Pattern for CGPA (e.g., 3.75, 4.0, etc.)\n",
        "    cgpa_matches = re.findall(cgpa_pattern, text)\n",
        "    return cgpa_matches\n",
        "\n",
        "email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "phone_pattern = r'\\b\\d{10}\\b|\\b\\d{3}[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b'\n",
        "\n",
        "# Folder paths for resumes and job descriptions\n",
        "resumes_folder = \"resume\"\n",
        "job_descriptions_folder = \"job\"\n",
        "\n",
        "resumes_files = [os.path.join(resumes_folder, file) for file in os.listdir(resumes_folder) if file.endswith(\".pdf\")]\n",
        "job_descriptions_files = [os.path.join(job_descriptions_folder, file) for file in os.listdir(job_descriptions_folder) if file.endswith(\".pdf\")]\n",
        "\n",
        "print(\"Available job descriptions:\")\n",
        "for i, job_desc_file in enumerate(job_descriptions_files):\n",
        "    print(f\"{i + 1}. {os.path.basename(job_desc_file)}\")\n",
        "\n",
        "selected_job_index = int(input(\"Enter the index of the job description you want to compare (1 to {}): \".format(len(job_descriptions_files))))\n",
        "selected_job_path = job_descriptions_files[selected_job_index - 1]\n",
        "selected_job_text = extract_text_from_pdf(selected_job_path)\n",
        "\n",
        "all_resumes_text = [extract_text_from_pdf(resume_path) for resume_path in resumes_files]\n",
        "\n",
        "# Preprocess job text and resume texts\n",
        "preprocessed_job_text = preprocess_text(selected_job_text)\n",
        "preprocessed_resumes_text = [preprocess_text(text) for text in all_resumes_text]\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(tokenizer=preprocess_text)\n",
        "\n",
        "# Fit the vectorizer on all resume texts and the selected job text\n",
        "vectorizer.fit(all_resumes_text + [selected_job_text])\n",
        "\n",
        "# Transform the job text and resume texts into TF-IDF vectors\n",
        "job_tfidf = vectorizer.transform([selected_job_text])\n",
        "resume_tfidf = vectorizer.transform(all_resumes_text)\n",
        "\n",
        "# Compute cosine similarity between job text and resume texts\n",
        "similarity_scores = cosine_similarity(job_tfidf, resume_tfidf)\n",
        "\n",
        "# Initialize a dictionary to store results\n",
        "results_data = {'Resume': [], 'Similarity Score': [], 'CGPA': [],'Total Score':[],'Email':[],'Contact':[]}\n",
        "\n",
        "# Extract CGPA from each resume and store results in the dictionary\n",
        "for i, resume_file in enumerate(resumes_files):\n",
        "    cgpa_matches = extract_cgpa(all_resumes_text[i])\n",
        "    cgpa = ', '.join(cgpa_matches) if cgpa_matches else 'Not found'\n",
        "    results_data['Resume'].append(os.path.basename(resume_file))\n",
        "    smScore=similarity_scores[0][i]*100\n",
        "    results_data['Similarity Score'].append(smScore)\n",
        "    results_data['CGPA'].append(cgpa)\n",
        "\n",
        "    emails = re.findall(email_pattern, all_resumes_text[i])\n",
        "    contacts = re.findall(phone_pattern, all_resumes_text[i])\n",
        "    if(cgpa==\"Not found\"):\n",
        "      # print(\"str\")\n",
        "      results_data['Total Score'].append(smScore)\n",
        "    else:\n",
        "      # print(\"int\")\n",
        "      sc=float(cgpa)+smScore\n",
        "      results_data['Total Score'].append(sc)\n",
        "\n",
        "    results_data['Email'].append(emails)\n",
        "    results_data['Contact'].append(contacts)\n",
        "\n",
        "# Create a DataFrame from the results dictionary\n",
        "results_df = pd.DataFrame(results_data)\n",
        "\n",
        "# Sort the DataFrame by similarity score in descending order\n",
        "results_df = results_df.sort_values(by='Similarity Score', ascending=False)\n",
        "\n",
        "# Display the results table\n",
        "print(\"\\nResults Table (sorted by Similarity Score in descending order):\")\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "ivv8k5kd1PaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac781da-e297-4c37-d8e5-264a509129a7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available job descriptions:\n",
            "1. CWS _ JD _ Software Interns.pdf\n",
            "2. JD - Security Researcher .pdf\n",
            "3. JD _ Head of Engineering (Cyber Security SaaS Startup) (1).pdf\n",
            "4. CWS - JD -Interns.pdf\n",
            "5. JD - Cloud Security.pdf\n",
            "6. CWS _ JD _ NodeJS Developer.pdf\n",
            "Enter the index of the job description you want to compare (1 to 6): 1\n",
            "\n",
            "Results Table (sorted by Similarity Score in descending order):\n",
            "                                     Resume  Similarity Score       CGPA  \\\n",
            "0                        Bhavik-cv-2024.pdf         55.625230  Not found   \n",
            "3             Priyanka Balivada - Eaton.pdf         50.975689  Not found   \n",
            "5  Priyanka Balivada - Barclays Updated.pdf         50.806383       9.28   \n",
            "2                   Nilesh_Pawar_Resume.pdf         50.586569       7.99   \n",
            "6               Naukri_OmTalathi[5y_0m].pdf         50.119062  Not found   \n",
            "8       Naukri_DikshaDeshbhratar[5y_0m].pdf         49.415659  Not found   \n",
            "4           Naukri_MANISHKHULLAR[3y_6m].pdf         47.026400        1.8   \n",
            "7                       KALPESH_GHORSE_.pdf         45.548719       8.16   \n",
            "1    Aditya's Resume NEW UPDATED RECENT.pdf         35.713665        7.8   \n",
            "9                   Resume_Nabaneet (1).pdf         33.925557  Not found   \n",
            "\n",
            "   Total Score                                        Email  \\\n",
            "0    55.625230                    [bhavikdoshi25@gmail.com]   \n",
            "3    50.975689                [priyanka.balivada22@vit.edu]   \n",
            "5    60.086383                [priyanka.balivada22@vit.edu]   \n",
            "2    58.576569                     [nilesh290402@gmail.com]   \n",
            "6    50.119062              [8390433344talathiom@gmail.com]   \n",
            "8    49.415659                   [dikshashende30@gmail.com]   \n",
            "4    48.826400                                           []   \n",
            "7    53.708719                   [ghorsekalpesh@gmail.com|]   \n",
            "1    43.513665          [kalhaneaditya.scoe.entc@gmail.com]   \n",
            "9    33.925557  [8896365169navneetlahiri@gmail.comGurugram]   \n",
            "\n",
            "                    Contact  \n",
            "0  [9167254066, 8169907181]  \n",
            "3              [9552690764]  \n",
            "5              [9552690764]  \n",
            "2                        []  \n",
            "6                        []  \n",
            "8              [9604250984]  \n",
            "4              [9518354126]  \n",
            "7              [7721027665]  \n",
            "1              [9156887017]  \n",
            "9                        []  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "import re  # Added import for regular expressions\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            text += pdf_reader.pages[page_num].extract_text()\n",
        "    return text\n",
        "\n",
        "def extract_cgpa_or_percentage(text):\n",
        "    cgpa_pattern = r'\\b(?:Cumulative GPA|CGPA|C.G.P.A|GPA):\\s*([\\d.]+)\\s*(?:/|out of)\\s*([\\d.]+)\\b'\n",
        "    percentage_pattern = r'\\b(?:Percentage|Percent):\\s*([\\d.]+)\\s*(?:/|out of)\\s*([\\d.]+%)\\b'\n",
        "\n",
        "    cgpa_match = re.search(cgpa_pattern, text, re.IGNORECASE)\n",
        "    percentage_match = re.search(percentage_pattern, text, re.IGNORECASE)\n",
        "\n",
        "    cgpa = cgpa_match.group(1) if cgpa_match else None\n",
        "    percentage = percentage_match.group(1) if percentage_match else None\n",
        "\n",
        "    return cgpa, percentage\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "def train_doc2vec_model(documents):\n",
        "    model = Doc2Vec(vector_size=20, min_count=2, epochs=50)\n",
        "    model.build_vocab(documents)\n",
        "    model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "    return model\n",
        "\n",
        "def calculate_similarity(model, text1, text2):\n",
        "    vector1 = model.infer_vector(preprocess_text(text1))\n",
        "    vector2 = model.infer_vector(preprocess_text(text2))\n",
        "    return model.dv.cosine_similarities(vector1, [vector2])[0]\n",
        "\n",
        "# Folder paths for resumes and job descriptions\n",
        "resumes_folder = \"resume\"\n",
        "job_descriptions_folder = \"job\"\n",
        "\n",
        "# List all PDF files in the folders\n",
        "resumes_files = [os.path.join(resumes_folder, file) for file in os.listdir(resumes_folder) if file.endswith(\".pdf\")]\n",
        "job_descriptions_files = [os.path.join(job_descriptions_folder, file) for file in os.listdir(job_descriptions_folder) if file.endswith(\".pdf\")]\n",
        "\n",
        "# Load job descriptions from the folder\n",
        "print(\"Available job descriptions:\")\n",
        "for i, job_desc_file in enumerate(job_descriptions_files):\n",
        "    print(f\"{i + 1}. {os.path.basename(job_desc_file)}\")\n",
        "\n",
        "selected_job_index = int(input(\"Enter the index of the job description you want to compare (1 to {}): \".format(len(job_descriptions_files))))\n",
        "selected_job_path = job_descriptions_files[selected_job_index - 1]\n",
        "selected_job_text = extract_text_from_pdf(selected_job_path)\n",
        "\n",
        "# Load all resumes from the folder\n",
        "all_resumes_text = [extract_text_from_pdf(resume_path) for resume_path in resumes_files]\n",
        "\n",
        "# Preprocess the documents and create TaggedDocuments for resumes\n",
        "tagged_resumes = [TaggedDocument(words=preprocess_text(text), tags=[str(i)]) for i, text in enumerate(all_resumes_text)]\n",
        "\n",
        "# Train Doc2Vec model for resumes\n",
        "model_resumes = train_doc2vec_model(tagged_resumes)\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "results_data = {'Resume': [], 'Similarity Score': [], 'CGPA': [], 'Percentage': []}\n",
        "\n",
        "# Compare the selected job description with all resumes\n",
        "for i, resume_text in enumerate(all_resumes_text):\n",
        "    similarity_score = calculate_similarity(model_resumes, resume_text, selected_job_text)\n",
        "    cgpa, percentage = extract_cgpa_or_percentage(resume_text)\n",
        "    results_data['Resume'].append(os.path.basename(resumes_files[i]))\n",
        "    results_data['Similarity Score'].append(similarity_score)\n",
        "    results_data['CGPA'].append(cgpa)\n",
        "    results_data['Percentage'].append(percentage)\n",
        "\n",
        "# Create a DataFrame\n",
        "results_df = pd.DataFrame(results_data)\n",
        "\n",
        "# Find the index of the highest similarity score\n",
        "highest_score_index = results_df['Similarity Score'].idxmax()\n",
        "\n",
        "# Get the filename and full path of the resume with the highest score\n",
        "highest_score_resume = resumes_files[highest_score_index]\n",
        "highest_score_resume_text = all_resumes_text[highest_score_index]\n",
        "\n",
        "# Extract name, email addresses, and contact numbers using regular expressions\n",
        "name_pattern = r'\\b[A-Z][a-z]+ [A-Z][a-z]+\\b'\n",
        "email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "phone_pattern = r'\\b\\d{10}\\b|\\b\\d{3}[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b'\n",
        "\n",
        "names = re.findall(name_pattern, highest_score_resume_text)\n",
        "emails = re.findall(email_pattern, highest_score_resume_text)\n",
        "contacts = re.findall(phone_pattern, highest_score_resume_text)\n",
        "\n",
        "# Combine extracted information into a single string for TF-IDF analysis\n",
        "combined_text = ' '.join([highest_score_resume_text] + names + emails + contacts)\n",
        "\n",
        "# Use TF-IDF to get high-weighted keywords\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform([combined_text])\n",
        "\n",
        "# Get feature names (words) and their corresponding TF-IDF scores\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "tfidf_scores = tfidf_matrix.toarray()[0]\n",
        "\n",
        "# Create a DataFrame to store keywords and their TF-IDF scores\n",
        "keywords_df = pd.DataFrame({'Keyword': feature_names, 'TF-IDF Score': tfidf_scores})\n",
        "\n",
        "# Sort DataFrame by TF-IDF scores in descending order\n",
        "keywords_df = keywords_df.sort_values(by='TF-IDF Score', ascending=False)\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nResume with the Highest Similarity Score:\")\n",
        "print(\"Filename:\", os.path.basename(highest_score_resume))\n",
        "print(\"Similarity Score:\", results_df.loc[highest_score_index, 'Similarity Score'])\n",
        "print(\"Extracted Name:\", names)\n",
        "print(\"Extracted Email Addresses:\", emails)\n",
        "print(\"Extracted Contact Numbers:\", contacts)\n",
        "print(\"Extracted CGPA:\", results_df.loc[highest_score_index, 'CGPA'])\n",
        "print(\"Extracted Percentage:\", results_df.loc[highest_score_index, 'Percentage'])\n",
        "\n",
        "# Display high-weighted keywords\n",
        "print(\"\\nHigh-Weighted Keywords:\")\n",
        "print(keywords_df.head(10))  # Displaying the top 10 keywords\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmeZK-MahYbV",
        "outputId": "04fcaa38-0b88-42ce-b3cc-5484e4c1d96e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available job descriptions:\n",
            "1. CWS _ JD _ Software Interns.pdf\n",
            "2. JD - Security Researcher .pdf\n",
            "3. JD _ Head of Engineering (Cyber Security SaaS Startup) (1).pdf\n",
            "4. CWS - JD -Interns.pdf\n",
            "5. JD - Cloud Security.pdf\n",
            "6. CWS _ JD _ NodeJS Developer.pdf\n",
            "Enter the index of the job description you want to compare (1 to 6): 1\n",
            "\n",
            "Resume with the Highest Similarity Score:\n",
            "Filename: Nilesh_Pawar_Resume.pdf\n",
            "Similarity Score: 0.7383026\n",
            "Extracted Name: ['Secondary School', 'Web Developer', 'Cooking Blog', 'Project Link', 'Project Link', 'Technical Skills', 'Earned Problem', 'Solving Badge']\n",
            "Extracted Email Addresses: ['nilesh290402@gmail.com']\n",
            "Extracted Contact Numbers: []\n",
            "Extracted CGPA: 7.99\n",
            "Extracted Percentage: None\n",
            "\n",
            "High-Weighted Keywords:\n",
            "         Keyword  TF-IDF Score\n",
            "96         india      0.234146\n",
            "146      project      0.187317\n",
            "115         link      0.187317\n",
            "128       nashik      0.187317\n",
            "0             00      0.140488\n",
            "46      cravings      0.140488\n",
            "93   implemented      0.140488\n",
            "105    inventory      0.140488\n",
            "45        coupon      0.140488\n",
            "195         user      0.140488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import nltk\n",
        "# from nltk.tokenize import word_tokenize\n",
        "# import PyPDF2\n",
        "# import pandas as pd\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "# import re  # Added import for regular expressions\n",
        "\n",
        "# nltk.download('punkt')\n",
        "\n",
        "# def extract_text_from_pdf(pdf_path):\n",
        "#     with open(pdf_path, 'rb') as file:\n",
        "#         pdf_reader = PyPDF2.PdfReader(file)\n",
        "#         text = \"\"\n",
        "#         for page_num in range(len(pdf_reader.pages)):\n",
        "#             text += pdf_reader.pages[page_num].extract_text()\n",
        "#     return text\n",
        "\n",
        "# def preprocess_text(text):\n",
        "#     return word_tokenize(text.lower())\n",
        "\n",
        "# def extract_cgpa(text):\n",
        "#     # Regular expression to match CGPA patterns\n",
        "#     cgpa_pattern = r'\\b\\d{1,2}(\\.\\d{1,2})?\\s*(?:CGPA|GPA)\\b'\n",
        "\n",
        "#     # Search for CGPA patterns in the text\n",
        "#     matches = re.findall(cgpa_pattern, text)\n",
        "\n",
        "#     # Return the first match (if any)\n",
        "#     return matches[0] if matches else None\n",
        "\n",
        "# # Folder paths for resumes and job descriptions\n",
        "# resumes_folder = \"resume\"\n",
        "# job_descriptions_folder = \"job\"\n",
        "\n",
        "# resumes_files = [os.path.join(resumes_folder, file) for file in os.listdir(resumes_folder) if file.endswith(\".pdf\")]\n",
        "# job_descriptions_files = [os.path.join(job_descriptions_folder, file) for file in os.listdir(job_descriptions_folder) if file.endswith(\".pdf\")]\n",
        "\n",
        "# print(\"Available job descriptions:\")\n",
        "# for i, job_desc_file in enumerate(job_descriptions_files):\n",
        "#     print(f\"{i + 1}. {os.path.basename(job_desc_file)}\")\n",
        "\n",
        "# selected_job_index = int(input(\"Enter the index of the job description you want to compare (1 to {}): \".format(len(job_descriptions_files))))\n",
        "# selected_job_path = job_descriptions_files[selected_job_index - 1]\n",
        "# selected_job_text = extract_text_from_pdf(selected_job_path)\n",
        "\n",
        "# all_resumes_text = [extract_text_from_pdf(resume_path) for resume_path in resumes_files]\n",
        "\n",
        "# preprocessed_job_text = preprocess_text(selected_job_text)\n",
        "# preprocessed_resumes_text = [preprocess_text(text) for text in all_resumes_text]\n",
        "\n",
        "# # Extract CGPA from the job description\n",
        "# job_cgpa = extract_cgpa(selected_job_text)\n",
        "# print(f\"CGPA from Job Description: {job_cgpa}\")\n",
        "\n",
        "# # Extract CGPA from each resume\n",
        "# resumes_cgpa = [extract_cgpa(resume_text) for resume_text in all_resumes_text]\n",
        "\n",
        "# # Add CGPA to the results DataFrame\n",
        "# results_df['CGPA'] = resumes_cgpa\n",
        "\n",
        "# # Display the updated results table\n",
        "# print(\"\\nResults Table with CGPA (sorted by Similarity Score in descending order):\")\n",
        "# print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hjCEnFZKXdK",
        "outputId": "b4391a49-f886-41ff-d146-bfecfce797ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available job descriptions:\n",
            "1. JD _ Head of Engineering (Cyber Security SaaS Startup) (1).pdf\n",
            "Enter the index of the job description you want to compare (1 to 1): 1\n",
            "CGPA from Job Description: None\n",
            "\n",
            "Results Table with CGPA (sorted by Similarity Score in descending order):\n",
            "                                   Resume  Similarity Score  CGPA\n",
            "3                     KALPESH_GHORSE_.pdf          0.083676  None\n",
            "2                 Nilesh_Pawar_Resume.pdf          0.068675  None\n",
            "0        Priyanka Balivada - Barclays.pdf          0.051192  None\n",
            "1  Aditya's Resume NEW UPDATED RECENT.pdf          0.048588  None\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}